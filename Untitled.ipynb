{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import tensorflow_datasets as tfds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, ds_info = tfds.load('omniglot', split=['train','test'],with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in ds[0]:\n",
    "    print(list(example.keys()))\n",
    "    alphabet = example[\"alphabet\"]\n",
    "    alphabet_char_id = example[\"alphabet_char_id\"]\n",
    "    image = example[\"image\"]\n",
    "    label = example[\"label\"]\n",
    "    print(alphabet)\n",
    "    print(alphabet_char_id)\n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_triplet(triplet):\n",
    "    plt.figure(figsize=(6,2))\n",
    "    for i in range(0, 3):\n",
    "        plt.subplot(1,3,i+1)\n",
    "        plt.imshow(triplet[i].shape)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_triplet([ds[0][0][\"image\"], ds[0][1][\"image\"], ds[0][2][\"image\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ds[0].take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for example in a:\n",
    "    print(example[\"image\"].shape)\n",
    "    examples.append(example[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_triplet(triplet):\n",
    "    plt.figure(figsize=(6,2))\n",
    "    for i in range(0, 3):\n",
    "        plt.subplot(1,3,i+1)\n",
    "        print(triplet[i].shape[0:2])\n",
    "        plt.imshow(np.reshape(triplet[i],(105,105,3)), cmap='binary')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_triplet(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://keras.io/examples/vision/reptile/\n",
    "def extraction(image, label):\n",
    "    # This function will shrink the Omniglot images to the desired size,\n",
    "    # scale pixel values and convert the RGB image to grayscale\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.resize(image, [28, 28])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    '''\n",
    "    This class will facilitate the creation of a few-shot dataset\n",
    "    from the Omniglot dataset that can be sampled from quickly while also\n",
    "    allowing to create new labels at the same time.\n",
    "    \n",
    "    Taken from https://keras.io/examples/vision/reptile/\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, training):\n",
    "        # Download the tfrecord files containing the omniglot data and convert to a dataset\n",
    "        split = \"train\" if training else \"test\"\n",
    "        ds = tfds.load('omniglot', split=split, as_supervised=True)\n",
    "        # Iterate over the dataset to get each individual image and its class,\n",
    "        # and put that data into a dictionary.\n",
    "        self.data = {}\n",
    "        \n",
    "        def extraction(image, label):\n",
    "            # This function will shrink the Omniglot images to the desired size,\n",
    "            # scale pixel values and convert the RGB image to grayscale\n",
    "            image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "            image = tf.image.rgb_to_grayscale(image)\n",
    "            image = tf.image.resize(image, [28, 28])\n",
    "            return image, label\n",
    "        \n",
    "        for image, label in ds.map(extraction):\n",
    "            image = image.numpy()\n",
    "            label = str(label.numpy())\n",
    "            if label not in self.data:\n",
    "                self.data[label] = []\n",
    "            self.data[label].append(image)\n",
    "            self.labels = list(self.data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, ds_info = tfds.load('omniglot', split=['train','test'],with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = ds[0], ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train = tfds.as_numpy(tfds.load('omniglot', split='train', batch_size=-1, as_supervised=True))\n",
    "# x_test, y_test = tfds.as_numpy(tfds.load('omniglot', split='test', batch_size=-1, as_supervised=True))\n",
    "\n",
    "train = Dataset(training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617\n"
     ]
    }
   ],
   "source": [
    "for key, value in train.data.items():\n",
    "    print(key)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Dataset(training = False)\n",
    "x_test, y_test = test.data, test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x_train:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_triplet(triplet):\n",
    "    plt.figure(figsize=(6,2))\n",
    "    for i in range(0, 3):\n",
    "        plt.subplot(1,3,i+1)\n",
    "        plt.imshow(np.reshape(triplet[i], (105, 105, 3)), cmap='binary')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_triplet([x_train[0], x_train[1], x_train[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(batch_size):\n",
    "    anchors = np.zeros((batch_size, 105, 105, 3))\n",
    "    positives = np.zeros((batch_size, 105, 105, 3))\n",
    "    negatives = np.zeros((batch_size, 105, 105, 3))\n",
    "    \n",
    "    for i in range(0, batch_size):\n",
    "        # inidex for anchor image\n",
    "        index = random.randint(0, 19280-1)\n",
    "        anc = x_train[index]\n",
    "        y = y_train[index]\n",
    "        \n",
    "        # np.where -> return tuple\n",
    "        # np.squeeze -> can change this tuple to ndarray\n",
    "        indices_for_pos = np.squeeze(np.where(y_train == y))\n",
    "        indices_for_neg = np.squeeze(np.where(y_train != y))\n",
    "        \n",
    "        pos = x_train[indices_for_pos[random.randint(0, len(indices_for_pos)-1)]]\n",
    "        neg = x_train[indices_for_neg[random.randint(0, len(indices_for_neg)-1)]]\n",
    "        \n",
    "        anchors[i] = anc\n",
    "        positives[i] = pos\n",
    "        negatives[i] = neg\n",
    "    return [anchors, positives, negatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_train == 963)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet = create_batch(10)\n",
    "plot_triplet([triplet[0][0], triplet[1][0], triplet[2][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, num_classes):\n",
    "    tf.keras.backend.clear_session()\n",
    "    cnn_model = keras.models.Sequential()\n",
    "    \n",
    "    # add layer\n",
    "    cnn_model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation=\"relu\", input_shape=input_shape))\n",
    "    cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(keras.layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "    cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(keras.layers.Conv2D(128, (3,3), activation=\"relu\"))\n",
    "    cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(keras.layers.Flatten())\n",
    "    cnn_model.add(keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l1(0.01)))\n",
    "    cnn_model.add(keras.layers.Dropout(0.25))\n",
    "    cnn_model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    '''\n",
    "    Function used to calculate Euclidean distance, which is the straight-line distance between two points\n",
    "    Taken from https://github.com/keras-team/keras/blob/master/examples/mnist_siamese.py\n",
    "    -args:\n",
    "        vects       A pair of vectors\n",
    "    -returns:\n",
    "        The distance of the pair\n",
    "    '''\n",
    "\n",
    "\n",
    "    x, y = vects\n",
    "\n",
    "    sum_square = keras.backend.sum(keras.backend.square(x - y), axis=1, keepdims=True)\n",
    "\n",
    "    return keras.backend.sqrt(keras.backend.maximum(sum_square, keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist_output_shape(shapes):\n",
    "    '''\n",
    "    Function used to return the Euclidean shape\n",
    "    Taken from https://github.com/keras-team/keras/blob/master/examples/mnist_siamese.py\n",
    "    '''\n",
    "\n",
    "    shape1, shape2 = shapes\n",
    "\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(margin, num_classes):\n",
    "    def loss(y_true, y_pred):\n",
    "        anc, pos, neg = y_pred[:, :num_classes], y_pred[:, num_classes:2*num_classes], y_pred[:, 2*num_classes:]\n",
    "        dp = tf.reduce_sum(tf.square(anc - pos), axis=1)\n",
    "        dn = tf.reduce_sum(tf.square(anc - neg), axis=1)\n",
    "        return tf.reduce_mean(tf.maximum(dp - dn + margin, 0.))\n",
    "    # return function\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, num_classes):\n",
    "    while True:\n",
    "        x = create_batch(batch_size)\n",
    "#         y = np.zeros((batch_size, 3*num_classes))\n",
    "        y = np.random.randint(0,1,size=(batch_size)).astype(np.float32)\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x_train.shape[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = create_cnn_model(input_size, num_classes)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_anc = tf.keras.layers.Input(shape=input_size)\n",
    "in_pos = tf.keras.layers.Input(shape=input_size)\n",
    "in_neg = tf.keras.layers.Input(shape=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_anc = cnn_model(in_anc)\n",
    "em_pos = cnn_model(in_pos)\n",
    "em_neg = cnn_model(in_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先合併，之後在 loss function 裡才要算距離\n",
    "# 前人的做法是先算完距離，在丟進去 loss function，所以 loss function 裡就沒有算距離\n",
    "out = tf.keras.layers.concatenate([em_anc, em_pos, em_neg], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tf.keras.models.Model(\n",
    "    [in_anc, in_pos, in_neg], \n",
    "    out\n",
    ")\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile(loss=triplet_loss(margin=0.2, num_classes=num_classes), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eopchs = 12\n",
    "#debug\n",
    "steps_per_epoch = int(19280/num_classes)\n",
    "epochs = 3\n",
    "_ = net.fit(\n",
    "    data_generator(num_classes, num_classes), \n",
    "    epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((1024, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.empty((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 633,
   "position": {
    "height": "655px",
    "left": "1023px",
    "right": "20px",
    "top": "52px",
    "width": "768px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
